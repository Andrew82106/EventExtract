# Model2: 基于意义段的迭代构图算法

## 算法概述

Model2 实现了 algorithm.md 中描述的第二种算法：基于意义段的迭代构图算法。该算法相比 Model1 的简单询问式方法，增加了以下特性：

1. **意义段分割**：将文本按照语义拆分成多个意义段
2. **支撑文本记录**：在构建图时记录每个节点和边的支撑文本
3. **迭代验证**：检查每个意义段是否在生成的图中有正确体现
4. **动态修正**：如果某个意义段未被覆盖，自动修改图结构

## 算法流程

1. 选择一个攻击类型，比如 suicide_ied
2. 从 `dataset/processedData/extracted_texts` 文件夹下找到该类型所有文本文件
3. 如果文件的数量大于15，就对所有文本抽样，选取15个文本
4. 遍历列表中的每一个文本
5. 对于每一个文本，首先让大语言模型按照句子的含义将文本拆分成多个意义段
6. 然后直接将整个文本扔给大语言模型，让大语言模型归纳出文本中事件的发展流程
7. 结合 `dataset/kairos_ontology.xlsx` 文件中的事件类型，让大语言模型把归纳出的事件的发展流程标准化为表中所规定的事件类型，并且用 networkx 库生成一张图，将事件类型作为节点，将事件关系作为边，并且将每个节点和边的支撑文本也存起来
8. 然后再次遍历之前生成的该文本的意义段，让大语言模型检查每个意义段是否在生成的图中有正确的体现，如果没有的话那就修改图的结构，保证每个意义段中的核心语义都在生成的图中
9. 然后将修改后的图保存为 json 文件，按照要求保存在 `result/model2/攻击类型/` 文件夹下
10. 然后采用和方法1相同的某种图算法，将这些图进行融合，得到最终的面向该攻击类型的事件骨架图

## 核心特性

### 1. 意义段分割（Segment Text）
- 使用 LLM 将长文本分割为多个语义单元
- 每个意义段包含一个完整的语义概念
- 为后续的迭代验证提供基础

### 2. 支撑文本（Support Text）
- 每个事件节点都记录其在原文中的支撑文本
- 每条时序边也记录其支撑文本
- 提高了图结构的可解释性和可追溯性

### 3. 迭代验证（Iterative Verification）
- 遍历所有意义段
- 检查每个意义段的核心语义是否在图中得到体现
- 对未覆盖的意义段提供修改建议

### 4. 自动修正（Auto-correction）
- 根据修改建议自动更新图结构
- 可能的操作：添加节点、添加边、修改节点、修改边
- 保证图结构能够更全面地反映原文内容

## 文件结构

```
model2/
├── __init__.py              # 包初始化文件
├── config.py                # 配置文件
├── data_loader.py           # 数据加载器
├── event_validator.py       # 事件类型验证器
├── graph_builder.py         # 图构建器（核心，包含迭代逻辑）
├── graph_merger.py          # 图融合器
├── main.py                  # 主程序
├── prompts.py               # 提示词模板
├── requirements.txt         # 依赖包列表
├── run.sh                   # 运行脚本
└── README.md               # 说明文档
```

## 依赖安装

```bash
pip install -r requirements.txt
```

主要依赖：
- networkx: 图数据结构
- pandas: 数据处理
- openpyxl: Excel 文件读取
- zhipuai: 智谱AI API

## 配置说明

在 `config.py` 中配置以下参数：

- `ZHIPU_API_KEY`: 智谱AI的API密钥
- `MAX_TEXT_SAMPLES`: 最大文本采样数（默认50）
- `ATTACK_TYPES`: 支持的攻击类型列表

## 使用方法

### 1. 命令行运行

```bash
# 使用默认攻击类型 (suicide_ied)
python main.py

# 指定攻击类型
python main.py --attack_type backpack_ied

# 指定API密钥
python main.py --attack_type suicide_ied --api_key your_api_key_here
```

### 2. 使用脚本运行

```bash
# 使用默认攻击类型
bash run.sh

# 指定攻击类型
bash run.sh backpack_ied
```

### 3. 作为模块导入

```python
from model2.main import main

# 运行算法
main(attack_type='suicide_ied', api_key='your_api_key')
```

## 输出说明

程序会在 `result/model2/攻击类型/` 目录下生成以下文件：

1. **单个图文件**: `graph_1.json`, `graph_2.json`, ...
   - 每个文本对应一个图文件
   - 包含节点（nodes）和边（edges）
   - 节点包含：事件类型、描述、支撑文本等
   - 边包含：时序关系、支撑文本等

2. **融合图文件**: `merged_graph_攻击类型.json`
   - 融合所有单个图得到的骨架图
   - 包含统计信息：出现频率、出现百分比等

## 与 Model1 的区别

| 特性 | Model1 | Model2 |
|------|--------|--------|
| 算法类型 | 简单询问式 | 基于意义段的迭代式 |
| 文本处理 | 直接提取事件 | 先分割意义段 |
| 支撑文本 | 不记录 | 记录每个节点和边的支撑文本 |
| 验证机制 | 一次性生成 | 迭代验证和修正 |
| 覆盖度 | 可能遗漏细节 | 确保每个意义段都被覆盖 |
| 运行时间 | 较快 | 较慢（因为多次LLM调用） |
| 准确性 | 一般 | 较高 |

## 算法优势

1. **更全面的覆盖**：通过意义段验证确保不遗漏重要信息
2. **更好的可解释性**：支撑文本使结果更易理解和验证
3. **自动修正能力**：能够发现和修正初次构图的不足
4. **更精细的控制**：分步骤的处理提供更多控制点

## 算法局限

1. **运行时间较长**：需要多次调用LLM API
2. **成本较高**：更多的API调用意味着更高的成本
3. **复杂性增加**：更多的步骤可能引入更多错误点

## 调试和日志

程序运行时会：
1. 在控制台输出详细的执行日志
2. 在 `logs/` 目录下保存带时间戳的日志文件
3. 输出验证报告，显示事件类型验证统计

## 评测

使用 `evaluate/` 目录下的评测工具对生成的图进行评估：

```bash
cd ../evaluate
python evaluator.py
```

评测指标：
- 主题重合F1值
- 事件序列匹配F1值

## 未来改进方向

1. 优化意义段分割算法
2. 减少LLM调用次数以降低成本
3. 引入并行处理提高速度
4. 增加更多的图质量验证指标
5. 支持更多类型的事件关系

## 贡献指南

如需改进此算法，请：
1. Fork 本项目
2. 创建特性分支
3. 提交改动
4. 发起 Pull Request

## 许可证

[根据项目实际情况填写]

## 联系方式

[根据项目实际情况填写]

